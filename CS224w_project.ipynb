{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A2d2MjyxqG0"
      },
      "source": [
        "# Movie Recommender System based on LightGCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO6HhJV4NsX6"
      },
      "source": [
        "## 1. Install Packages and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxoenua1-u5r"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "# %%capture\n",
        "# import torch\n",
        "# import os\n",
        "# os.environ['TORCH'] = torch.__version__\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "outputs": [],
      "source": [
        "# import required modules\n",
        "import torch \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import Tensor, nn, optim\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_sparse import SparseTensor, matmul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXnpUp2yNqzH"
      },
      "source": [
        "## 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhNjo7fqslj_"
      },
      "source": [
        "MovieLens 100k is a well-known movie recommendation dataset that contains 100,000 movie ratings from 943 users on 1,682 movies. Each user has rated at least 20 movies on a scale of 1 to 5, and the data is provided in a matrix format where each row represents a user and each column represents a movie. The dataset also includes additional information such as movie genre and release year. MovieLens 100k is often used as a benchmark for evaluating movie recommendation models and algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRC_IazQ4Oj",
        "outputId": "e46a08ca-5cd8-4547-a16c-081fae37dae6"
      },
      "outputs": [],
      "source": [
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0bzq0x6QC3U"
      },
      "source": [
        "The `ratings.csv` dataset links users (identified by `userId`) and movies (identified by `movieId`). Our initial objective is to construct a dictionary that maps each entry's ID to a unique value within the range `{ 0, ..., num_rows - 1 }`. This mapping is beneficial since it reduces the size of the adjacency matrix. We then generate an `edge_index` matrix from `ratings.csv` with dimensions `[2, num_ratings]`. The first row contains the mapped userId, while the second row has the mapped `movieId`. A specific column corresponds to a connection (or rating) between a user and a movie. The `edge_index` tensor is a crucial component for message propagation throughout the graph network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLEBcsyv5abc"
      },
      "outputs": [],
      "source": [
        "def preprocessing(movie_path, rating_path):\n",
        "  '''\n",
        "    Parameters:\n",
        "         movie_path (str): A string representing the file path to the movies dataset.\n",
        "         rating_path (str): A string representing the file path to the ratings dataset.\n",
        "\n",
        "    Returns:\n",
        "         edge_index (torch.Tensor): the indices of edges in the adjacency matrix for the ratings dataset.\n",
        "         num_users (int): number of unique users in the ratings dataset.\n",
        "         num_movies (int): number of unique movies in the ratings dataset.\n",
        "         user_mapping (pd.DataFrame): the list that map user id to continguous new ids\n",
        "         movie_df (pd.DataFrame): the movie dataset\n",
        "         rating_df (pd.DataFrame): the rating dataset\n",
        "  '''\n",
        "  # load movies and ratings dataset\n",
        "  movie_df = pd.read_csv(movie_path, index_col = 'movieId')\n",
        "  rating_df = pd.read_csv(rating_path, index_col = 'userId')\n",
        "\n",
        "  # create mapping to continous range\n",
        "  movie_mapping = {idx: i for i, idx in enumerate(movie_df.index.unique())}\n",
        "  user_mapping = {idx: i for i, idx in enumerate(rating_df.index.unique())}\n",
        "  num_users, num_movies = len(rating_df.index.unique()), len(movie_df.index.unique())\n",
        "\n",
        "  rating_df = pd.read_csv(rating_path)\n",
        "  edge_index = None\n",
        "  users = [user_mapping[idx] for idx in rating_df['userId']]\n",
        "  movies = [movie_mapping[idx] for idx in rating_df['movieId']]\n",
        "\n",
        "  # filter for edges with a high rating\n",
        "  ratings = rating_df['rating'].values\n",
        "  recommend_bool = torch.from_numpy(ratings).view(-1, 1).to(torch.long) >= 4\n",
        "\n",
        "  edge_index = [[],[]]\n",
        "  for i in range(recommend_bool.shape[0]):\n",
        "    if recommend_bool[i]:\n",
        "      edge_index[0].append(users[i])\n",
        "      edge_index[1].append(movies[i])\n",
        "\n",
        "  edge_index = torch.tensor(edge_index)\n",
        "  return edge_index, num_users, num_movies, \\\n",
        "  movie_mapping, user_mapping, movie_df, rating_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm-VDQZA_GAP"
      },
      "outputs": [],
      "source": [
        "edge_index, num_users, num_movies, \\\n",
        "movie_mapping, user_mapping, \\\n",
        "movie_df, rating_df = preprocessing(movie_path, rating_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gth7ZSb2tic9"
      },
      "source": [
        "### A peek into the MovieLens 100K dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4N5c7jhbZ9u"
      },
      "source": [
        "Let's take a look into the MovieLens dataset. We can see the `movie.csv` has the following format: `movieId title genres`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "hJ1QdoYStY9z",
        "outputId": "3c6c0827-8d3b-4c3d-8a4e-2fa09632ede2"
      },
      "outputs": [],
      "source": [
        "# format for movie\n",
        "movie_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6n1vPXtb62V"
      },
      "source": [
        "The `rating.csv` has the following format of `userId, movieId, rating, timestamp`. For the raitng prediction task, we only need the first three fields for the purpose of our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ZAdRhX80twp8",
        "outputId": "55da0216-ea4b-48a3-beca-032e3071b469"
      },
      "outputs": [],
      "source": [
        "# format for ratings\n",
        "rating_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdxnMjKHtDhG"
      },
      "source": [
        "We also need to know the rating scales because we need to determine beyond what scores we can say that a user likes the movies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az7ncS0yuyWF",
        "outputId": "6edd9509-b800-4406-ffc5-101021c7070f"
      },
      "outputs": [],
      "source": [
        "# what are the ratings\n",
        "sorted(pd.unique(rating_df['rating']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h4S1ncBvK8d"
      },
      "source": [
        "### Prepare datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVRWWdhbRqhu"
      },
      "source": [
        "Next, we divide the complete dataset into training, validation, and testing sets. The partition is made based on the edges in the graph. More specifically, we randomly separate the data into three groups with an 80/10/10 split ratio. This implies that each group will contain a portion of the `edge_index` subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9op9aVbTFIf"
      },
      "outputs": [],
      "source": [
        "# split the edges into train set and test set\n",
        "num_ratings = edge_index.shape[1]\n",
        "rating_indices = np.arange(num_ratings)\n",
        "\n",
        "indices_train, indices_val_test = train_test_split(rating_indices, test_size = 0.2, random_state = 42)\n",
        "indices_val, indices_test = train_test_split(indices_val_test, test_size = 0.5, random_state = 42)\n",
        "\n",
        "# slice the whole dataset by split indices, then convert to SparseTensor for later training\n",
        "def generate_edge(edge_indices):\n",
        "  '''\n",
        "  Paramters:\n",
        "      edge_indices (np.ndarray): An array representing the indices of edges in the dataset.\n",
        "\n",
        "  Returns:\n",
        "      sub_edge_index (torch.Tensor): indices of edges in the specified subset.\n",
        "      edge_index_sparse (SparseTensor): A sparse tensor representing the adjacency matrix for the subset of edges.\n",
        "  '''\n",
        "  sub_edge_index = edge_index[:, edge_indices]\n",
        "  num_nodes = num_users + num_movies\n",
        "  edge_index_sparse = SparseTensor(row = sub_edge_index[0],\n",
        "                                   col = sub_edge_index[1],\n",
        "                                   sparse_sizes = (num_nodes, num_nodes))\n",
        "  return sub_edge_index, edge_index_sparse\n",
        "\n",
        "train_edge_index, train_sparse_edge_index = generate_edge(indices_train)\n",
        "val_edge_index, val_sparse_edge_index = generate_edge(indices_val)\n",
        "test_edge_index, test_sparse_edge_index = generate_edge(indices_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvZpaxT_aFCd"
      },
      "source": [
        "During the training phase, we will use mini-batches and select a number of positive and negative edges within each batch. Positive edges refer to observed or training user-item interactions. We aim to punish negative edges during training by allocating them with a greater loss. To achieve this, we will make use of the PyG function called `structured_negative_sampling,` which selects a negative edge for every positive edge in the graph as defined by `edge_index`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z7I9eJfzIpq",
        "outputId": "6bd21a1c-8ebf-406a-bbfa-bdbdd44b2d2a"
      },
      "outputs": [],
      "source": [
        "print(train_sparse_edge_index)\n",
        "print(train_edge_index.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uxt8LxCnkE7",
        "outputId": "084d60dd-0197-4fec-d136-9b15841afbd6"
      },
      "outputs": [],
      "source": [
        "edges = structured_negative_sampling(train_edge_index)\n",
        "edges = torch.stack(edges, dim=0)\n",
        "edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqKI1VduKcwf"
      },
      "outputs": [],
      "source": [
        "def mini_batch_sample(batch_size, edge_index):\n",
        "    \"\"\"\n",
        "    Randomly samples indices of a minibatch given an adjacency matrix.\n",
        "    These tensors represent the indices of the sampled minibatch, where:\n",
        "    - user indices: indices of the users in the sampled edges\n",
        "    - positive item indices: indices of the positive items in the sampled edges\n",
        "    - negative item indices: indices of the negative items in the sampled edges\n",
        "\n",
        "    Parameters:\n",
        "    batch_size (int): The desired minibatch size.\n",
        "    edge_index (torch.Tensor): A 2 by N tensor representing the edges.\n",
        "\n",
        "    Returns:\n",
        "    user indices, positive item indices, negative item indices (torch.Tensor)\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = torch.randperm(edges.shape[1])[:batch_size]\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6uMVxdDqUAT"
      },
      "source": [
        "## 3.Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF-_2S6AnvXB"
      },
      "source": [
        "LightGCN is a recommender system model that belongs to the family of graph convolutional networks (GCNs). The primary objective of LightGCN is to provide personalized recommendations by exploiting the user-item interaction graph's structure. Unlike other graph-based recommendation methods that use complex graph neural networks (GNNs), LightGCN omits the feature transformation and non-linearity, which requires fewer parameters and has a faster training time. The model's architecture involves performing several layers of graph convolutions to propagate user-item embeddings, which are then used to generate personalized recommendations. LightGCN has demonstrated competitive performance in terms of recommendation quality while being computationally efficient. For more information, you can find the [orginal paper](https://arxiv.org/pdf/2002.02126.pdf) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Encoder and Decoder\n",
        "The LightGCN model's only adjustable parameters are the initial embeddings for each user and item in the 0-th layer, denoted as $e_u^{(0)}$ and $e_i^{(0)}$, respectively. The final embeddings for all users and items, represented as $e_u$ and $e_i$, are created by merging the embeddings acquired at each propagation layer using the following formula.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "outputs": [],
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"\n",
        "    LightGCN Model, see reference: https://arxiv.org/abs/2002.02126\n",
        "    We omit a dedicated class for LightGCNConvs for easy access to embeddings\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, hidden_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.users_emb = nn.Embedding(self.num_users, self.hidden_dim)\n",
        "        self.items_emb = nn.Embedding(self.num_items, self.hidden_dim)\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        \"\"\"\n",
        "        Forward pass of the LightGCN model. Returns the init and final\n",
        "        embeddings of the user and item\n",
        "        \"\"\"\n",
        "        edge_index_norm = gcn_norm(edge_index, False)\n",
        "\n",
        "        # The first layer, concat embeddings\n",
        "        x0 = torch.cat([self.users_emb.weight, self.items_emb.weight])\n",
        "        xs = [x0]\n",
        "        xi = x0\n",
        "\n",
        "        # pass x to the next layer\n",
        "        for i in range(self.num_layers):\n",
        "            xi = self.propagate(edge_index_norm, x=xi)\n",
        "            xs.append(xi)\n",
        "        # print(\"Length of xs : \", len(xs))\n",
        "        xs = torch.stack(xs, dim=1)\n",
        "        x_final = torch.mean(xs, dim=1)\n",
        "\n",
        "        users_emb, items_emb = \\\n",
        "        torch.split(x_final, [self.num_users, self.num_items])\n",
        "\n",
        "        return users_emb, self.users_emb.weight, items_emb, self.items_emb.weight\n",
        "\n",
        "    def message(self, x):\n",
        "        return x\n",
        "\n",
        "    def propagate(self, edge_index_norm, x):\n",
        "        x = self.message_and_aggregate(edge_index_norm, x)\n",
        "        return x\n",
        "\n",
        "    def message_and_aggregate(self, edge_index_norm, x):\n",
        "        return matmul(edge_index_norm, x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "\n",
        "The model's training objective in LightGCN is based on a pairwise Bayesian Personalized Ranking (BPR) loss. This loss aims to ensure that the model's predictions for positive samples are higher than those for negative samples for each user. The BPR loss function is defined as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2\n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: L-2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "outputs": [],
      "source": [
        "def bpr_loss(users_emb, user_emb_0, pos_emb, pos_emb_0, neg_emb, neg_emb_0, lambda_val):\n",
        "    \"\"\"\n",
        "    Calculate the Bayesian Personalzied Ranking loss.\n",
        "\n",
        "    Parameters:\n",
        "    users_emb (torch.Tensor): The final output of user embedding\n",
        "    user_emb_0 (torch.Tensor): The initial user embedding\n",
        "    pos_emb (torch.Tensor):  The final positive item embedding\n",
        "    pos_emb_0 (torch.Tensor): The initial item embedding\n",
        "    neg_emb (torch.Tensor): The final negtive item embedding\n",
        "    neg_emb_0 (torch.Tensor): The inital negtive item embedding\n",
        "    lambda_val (float): L2 regulatization strength\n",
        "\n",
        "    Returns:\n",
        "    loss (float): The BPR loss\n",
        "    \"\"\"\n",
        "    pos_scores = torch.sum(users_emb * pos_emb, dim=1)\n",
        "    neg_scores = torch.sum(users_emb * neg_emb, dim=1)\n",
        "    losses = -torch.log(torch.sigmoid(pos_scores - neg_scores))\n",
        "    loss = torch.mean(losses) + lambda_val * \\\n",
        "    (torch.norm(users_emb_0) + torch.norm(pos_emb_0) + torch.norm(neg_emb_0))\n",
        "    # print(\"Loss was : \", loss)\n",
        "    # print(\"Pos Score : \", torch.sum(pos_scores))\n",
        "    # print(\"Neg Score Emb : \", torch.sum(neg_scores))\n",
        "    # print(\"pos emb : \", pos_emb.shape)\n",
        "    # input()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-BrXDrgqt18"
      },
      "source": [
        "## 4.Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5hSZPcgWe7-"
      },
      "source": [
        "The evaluation metric we will use is **Recall@K**, it is defined as the proportion of relevant items that are recommended to a user among the top-K items recommended by the algorithm. \\\\\n",
        "For each user $u$, \\\\\n",
        "Let $P_{u}$ be a set of positive items the user will interact in the future. \\\\\n",
        "Let $R_{u}$ be a set of items recommended by the model, in top-K recommendation, $|R_{u}| = K$. Items that users has already interacted are excluded.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1Ea3_y0eLNNKZT2p13Sa-umZccVuNtRvo)\n",
        "\n",
        "**Recall@K** for user $u$ is $|P_{u}\\cap R_{u}| / |P_{u}|$. \\\\\n",
        "The final Recall@K is computed by averaging the recall values across all users.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIUu82bph3q1"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, edge_index, sparse_edge_index, mask_index, k, lambda_val):\n",
        "    \"\"\"\n",
        "    Evaluates model loss and metrics including recall, precision on the\n",
        "    Parameters:\n",
        "    model: LightGCN model to evaluate.\n",
        "    edge_index (torch.Tensor): Edges for the split to evaluate.\n",
        "    sparse_edge_index (torch.SparseTensor): Sparse adjacency matrix.\n",
        "    mask_index(torch.Tensor): Edges to remove from evaluation, in the form of a list.\n",
        "    k (int): Top k items to consider for evaluation.\n",
        "\n",
        "    Returns: loss, recall, precision\n",
        "        - loss: The loss value of the model on the given split.\n",
        "        - recall: The recall value of the model on the given split.\n",
        "        - precision: The precision value of the model on the given split.\n",
        "    \"\"\"\n",
        "    # get embeddings and calculate the loss\n",
        "    users_emb, users_emb_0, items_emb, items_emb_0 = model.forward(sparse_edge_index)\n",
        "    edges = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
        "\n",
        "    user_indices, pos_indices, neg_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb, users_emb_0 = users_emb[user_indices], users_emb_0[user_indices]\n",
        "    pos_emb, pos_emb_0 = items_emb[pos_indices], items_emb_0[pos_indices]\n",
        "    neg_emb, neg_emb_0 = items_emb[neg_indices], items_emb_0[neg_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb, users_emb_0, pos_emb, pos_emb_0,\n",
        "                    neg_emb, neg_emb_0, lambda_val).item()\n",
        "\n",
        "    users_emb_w = model.users_emb.weight\n",
        "    items_emb_w = model.items_emb.weight\n",
        "\n",
        "    # set ratings matrix between every user and item, mask out existing ones\n",
        "    rating = torch.matmul(users_emb_w, items_emb_w.T)\n",
        "\n",
        "    for index in mask_index:\n",
        "        user_pos_items = get_positive_items(index)\n",
        "        masked_users = []\n",
        "        masked_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            masked_users.extend([user] * len(items))\n",
        "            masked_items.extend(items)\n",
        "\n",
        "        rating[masked_users, masked_items] = float(\"-inf\")\n",
        "\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users and actual ratings for evaluation\n",
        "    users = edge_index[0].unique()\n",
        "    test_user_pos_items = get_positive_items(edge_index)\n",
        "\n",
        "    actual_r = [test_user_pos_items[user.item()] for user in users]\n",
        "    pred_r = []\n",
        "\n",
        "    for user in users:\n",
        "        items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in items, top_K_items[user]))\n",
        "        # print(\"User : \", user)\n",
        "        # print(\"Actual Movies : \", items)\n",
        "        # print(\"labels        : \", label)\n",
        "        # print(\"Length of labels : \", len(label))\n",
        "        # input()\n",
        "        pred_r.append(label)\n",
        "\n",
        "    pred_r = torch.Tensor(np.array(pred_r).astype('float'))\n",
        "\n",
        "\n",
        "    correct_count = torch.sum(pred_r, dim=-1)\n",
        "    # number of items liked by each user in the test set\n",
        "    liked_count = torch.Tensor([len(actual_r[i]) for i in range(len(actual_r))])\n",
        "\n",
        "    recall = torch.mean(correct_count / liked_count)\n",
        "    precision = torch.mean(correct_count) / k\n",
        "\n",
        "\n",
        "    return loss, recall, precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "outputs": [],
      "source": [
        "# helper method to get positive items for train/test sets\n",
        "def get_positive_items(edge_index):\n",
        "    \"\"\"\n",
        "    Return positive items for all users in form of list\n",
        "    Parameters:\n",
        "      edge_index (torch.Tensor): The edge index representing the user-item interactions.\n",
        "    Returns:\n",
        "      pos_items (torch.Tensor): A list containing the positive items for all users.\n",
        "    \"\"\"\n",
        "    pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in pos_items:\n",
        "            pos_items[user] = []\n",
        "        pos_items[user].append(item)\n",
        "    return pos_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "outputs": [],
      "source": [
        "def recallAtK(actual_r, pred_r, k):\n",
        "    \"\"\"\n",
        "    Return recall at k and precision at k\n",
        "    \"\"\"\n",
        "    correct_count = torch.sum(pred_r, dim=-1)\n",
        "    # number of items liked by each user in the test set\n",
        "    liked_count = torch.Tensor([len(actual_r[i]) for i in range(len(actual_r))])\n",
        "\n",
        "    recall = torch.mean(correct_count / liked_count)\n",
        "    precision = torch.mean(correct_count) / k\n",
        "\n",
        "    return recall.item(), precision.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "## 5.Training Process\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*) with the default model config:\n",
        "\n",
        "Loss: 0.31, Recall@K: 0.13, and Precision@K: 0.035"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "outputs": [],
      "source": [
        "# model configurations\n",
        "config = {\n",
        "    'batch_size': 256,\n",
        "    'num_epoch': 5,\n",
        "    'epoch_size': 10,\n",
        "    'lr': 1e-3,\n",
        "    'lr_decay': 0.9,\n",
        "    'topK': 20,\n",
        "    'lambda': 1e-6,\n",
        "    'hidden_dim': 32,\n",
        "    'num_layer': 3,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49JDkBtKTfE-"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = LightGCN(num_users, num_movies, config['hidden_dim'], config['num_layer'])\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=config['lr_decay'])\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "9ad712e5-cd77-425f-b6c5-6dfd4627dd40"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "recalls= []\n",
        "\n",
        "for epoch in range(config['num_epoch']):\n",
        "  for iter in range(config['epoch_size']):\n",
        "    # forward propagation\n",
        "    users_emb, users_emb_0, items_emb, items_emb_0 = \\\n",
        "        model.forward(train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_indices, neg_indices = \\\n",
        "        mini_batch_sample(config['batch_size'], train_edge_index)\n",
        "\n",
        "    user_indices = user_indices.to(device)\n",
        "    pos_indices = pos_indices.to(device)\n",
        "    neg_indices = neg_indices.to(device)\n",
        "\n",
        "    users_emb, users_emb_0 = users_emb[user_indices], users_emb_0[user_indices]\n",
        "    pos_emb, pos_emb_0 = items_emb[pos_indices], items_emb_0[pos_indices]\n",
        "    neg_emb, neg_emb_0 = items_emb[neg_indices], items_emb_0[neg_indices]\n",
        "\n",
        "    # loss computation\n",
        "    loss = bpr_loss(users_emb, users_emb_0,\n",
        "                    pos_emb, pos_emb_0,\n",
        "                    neg_emb, neg_emb_0,\n",
        "                    config['lambda'])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, recall, precision = evaluation(model, val_edge_index,\n",
        "                                            val_sparse_edge_index,\n",
        "                                            [train_edge_index],\n",
        "                                            config['topK'],\n",
        "                                            config['lambda'])\n",
        "    model.train()\n",
        "    recalls.append(recall)\n",
        "\n",
        "\n",
        "    print('Epoch {:d}: train_loss: {:.4f}, val_loss: {:.4f}, recall: {:.10f}, precision: {:.4f}'\\\n",
        "          .format(epoch, loss, val_loss, recall, precision))\n",
        "  # train_losses.append(loss.item())\n",
        "  # val_losses.append(val_loss)\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sAViHQux6kg"
      },
      "source": [
        "### Visualize the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(recalls)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "nLcdvV5iXBSv",
        "outputId": "01149a8a-1b4c-4491-9612-b0a4eb6d0a41"
      },
      "outputs": [],
      "source": [
        "epochs = range(config['num_epoch'])\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "ax.plot( train_losses, color='r', label='Train', alpha=1)\n",
        "# ax.plot(epochs, val_losses, color='b', label='Validation', alpha=1)\n",
        "ax.grid(color='g', ls='-.', lw=0.5)\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Losses')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p45TlRNsFFi"
      },
      "source": [
        "### Evaluate on the test set\n",
        "Now we can evaluate on the test set to see how our model perform:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6UjCTMQ_N5e",
        "outputId": "426ca290-542c-4b3b-d4c6-ee1afd13b2e2"
      },
      "outputs": [],
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_loss, test_recall, test_precision \\\n",
        "    = evaluation(model,\n",
        "                test_edge_index,\n",
        "                test_sparse_edge_index,\n",
        "                [train_edge_index, val_edge_index],\n",
        "                config['topK'],\n",
        "                config['lambda'])\n",
        "\n",
        "\n",
        "print('Test set: train_loss: {:.4f}, recall: {:.4f}, precision: {:.4f}'\\\n",
        "        .format(test_loss, test_recall, test_precision))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "# Make New Recommendatios for a Given User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "outputs": [],
      "source": [
        "def predict(user_id, topK):\n",
        "    '''\n",
        "    Make top K recommendations to the user\n",
        "    '''\n",
        "    # read movie and uesr info\n",
        "    model.eval()\n",
        "    df = pd.read_csv(movie_path)\n",
        "    movie_titles = pd.Series(df.title.values, index=df.movieId).to_dict()\n",
        "    movie_genres = pd.Series(df.genres.values, index=df.movieId).to_dict()\n",
        "    pos_items = get_positive_items(edge_index)\n",
        "    user = user_mapping[user_id]\n",
        "    user_emb = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ user_emb\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(pos_items[user]) + topK)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in pos_items[user]]\n",
        "    topk_movies = movies[:topK]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values())\\\n",
        "                                            .index(movie)] for movie in movies]\n",
        "    titles = [movie_titles[id] for id in movie_ids]\n",
        "    genres = [movie_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(\"User {:d} liked these movies:\".format(user_id))\n",
        "    for i in range(topK):\n",
        "        print(\"{:s}, {:s} \".format(titles[i], genres[i]))\n",
        "\n",
        "    print('====================================================================')\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in pos_items[user]]\n",
        "    topk_movies = movies[:topK]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values())\\\n",
        "    .index(movie)] for movie in movies]\n",
        "    titles = [movie_titles[id] for id in movie_ids]\n",
        "    genres = [movie_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(\"Here are the movies that we think the user will enjoy:\")\n",
        "    for i in range(topK):\n",
        "        print(\"{:s}, {:s} \".format(titles[i], genres[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CygVPMklajo"
      },
      "source": [
        "### Try it out!\n",
        "Now you can explore with different user ID (1 to 943) and the number of movies to recommend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSFgwnaecWBw",
        "outputId": "f7b91cd2-85b0-4ce7-8cf8-ce072a5da5cd"
      },
      "outputs": [],
      "source": [
        "predict(123, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9rpyRBqvLmC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
